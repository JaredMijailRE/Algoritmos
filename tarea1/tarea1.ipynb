{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para esta tarea se pensó primero en como cargar los datos para ello usaremos python, con pandas y numpy, además de eso el procesamiento como tal de los datos, no es complejo, sin embargo para hacerlo más interesante utilizaremos numba con python para realizarlo de manera paralela ya que recientemente hicimos un curso del mismo, algo ha resaltar que ya podemos anticipar es que los resultados vas a aparecer en desorden, además de que tal vez por la cantidad de datos el programa resulte más lento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0    b'NVIDIA GeForce RTX 3070'                              [SUPPORTED]\n",
      "                      Compute Capability: 8.6\n",
      "                           PCI Device ID: 0\n",
      "                              PCI Bus ID: 8\n",
      "                                    UUID: GPU-35b3c601-3795-7d80-d202-66c78dcbdd65\n",
      "                                Watchdog: Enabled\n",
      "                            Compute Mode: WDDM\n",
      "             FP32/FP64 Performance Ratio: 32\n",
      "Summary:\n",
      "\t1/1 devices are supported\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías\n",
    "from numba import cuda\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(cuda.detect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Creditos</th>\n",
       "      <th>Nota</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>45.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>46.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>30.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Creditos  Nota\n",
       "0         3  45.4\n",
       "1         4  46.3\n",
       "2         3  50.0\n",
       "3         4  30.4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos los datos\n",
    "A = pd.read_csv('datos.csv')\n",
    "A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Continuación se empezó a pensar en qué cosas se pueden realizar en paralelo a través de un kernel, por ello vamos a crear una función que nos devuelva la suma de todas las notas teniendo en cuenta los créditos y cuantas notas hay, osea la cantidad de créditos totales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que sume los datos y nos diga cuantos datos hay\n",
    "def preProcessing(data):\n",
    "    total_creditos = data['Creditos'].sum()\n",
    "    total_notas = (data['Creditos'] * data['Nota']).sum()\n",
    "    return np.array([total_creditos], dtype=np.float64), np.array([total_notas], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo que si podemos paralelizar es el calculo final dados todos los posibles resultados de la nota de algoritmos, de forma que con numba vamos a utilizar cuda para definir nuestra kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def solution(notas, creditos, resultados, notaMateria):\n",
    "    idx = cuda.threadIdx.x \n",
    "    calificacion = (idx + 1) * 0.5\n",
    "    notas_ = notas[0] + (calificacion * 3)\n",
    "    resultados[idx] = notas_ / (creditos[0] + 3)\n",
    "    notaMateria[idx] = calificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora como tal vamos a utilizar las funciones, para ello va a ser necesario cargar el resultado de preProcessing en la memoria de la tarjeta gráfica de forma que sea más eficiente el programa, además es ideal pues solo tenemos que hacer lecturas en el programa.\n",
    "\n",
    "Además de esto y por error previamente se pensaba que en el kernel se podía hacer un print directamente, sin embargo es necesario igual crear un array donde vamos a cargar muestras respuestas, copiarlo a la gpu, y después devolverlo a la cpu, para ser exactos son dos arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota materia 0.5: Nota final calculada: 34.97058868408203\n",
      "Nota materia 1.0: Nota final calculada: 35.05882263183594\n",
      "Nota materia 1.5: Nota final calculada: 35.14706039428711\n",
      "Nota materia 2.0: Nota final calculada: 35.235294342041016\n",
      "Nota materia 2.5: Nota final calculada: 35.32352828979492\n",
      "Nota materia 3.0: Nota final calculada: 35.411766052246094\n",
      "Nota materia 3.5: Nota final calculada: 35.5\n",
      "Nota materia 4.0: Nota final calculada: 35.588233947753906\n",
      "Nota materia 4.5: Nota final calculada: 35.67647171020508\n",
      "Nota materia 5.0: Nota final calculada: 35.764705657958984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documentos\\GitHub\\Algoritmos\\.venv\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "creditos, notas = preProcessing(A)\n",
    "result = np.zeros(10, dtype=np.float32)\n",
    "materias = np.zeros(10, dtype=np.float32)\n",
    "d_cre = cuda.to_device(creditos)\n",
    "d_not = cuda.to_device(notas)\n",
    "d_res = cuda.to_device(result)\n",
    "d_ind = cuda.to_device(result)\n",
    "\n",
    "solution[1, 10](d_not, d_cre, d_res, d_ind)\n",
    "\n",
    "resultado = d_res.copy_to_host()\n",
    "notaMateria = d_ind.copy_to_host()\n",
    "\n",
    "for i, res in enumerate(resultado):\n",
    "    print(f'Nota materia {notaMateria[i]}: Nota final calculada: {res}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
